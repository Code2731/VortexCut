// FFmpeg Decoder ëª¨ë“ˆ (ffmpeg-next with hardware acceleration)
// ì•„í‚¤í…ì²˜: ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜ ë””ì½”ë” + EOF/ì—ëŸ¬ ì•ˆì „ ì²˜ë¦¬

use ffmpeg_next as ffmpeg;
use std::path::Path;

/// ë¹„ë””ì˜¤ í”„ë ˆì„ ë°ì´í„°
#[derive(Debug, Clone)]
pub struct Frame {
    pub width: u32,
    pub height: u32,
    pub format: PixelFormat,
    pub data: Vec<u8>,
    pub timestamp_ms: i64,
}

/// í”½ì…€ í¬ë§·
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PixelFormat {
    RGBA,
    RGB,
    YUV420P,
}

/// ë””ì½”ë” ìƒíƒœ ë¨¸ì‹ 
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum DecoderState {
    Ready,          // ì •ìƒ ë™ì‘ ê°€ëŠ¥
    EndOfStream,    // íŒŒì¼ ë ë„ë‹¬ (seekìœ¼ë¡œ ë³µêµ¬ ê°€ëŠ¥)
    Error,          // ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬
}

/// ë””ì½”ë”© ê²°ê³¼ (ì—ëŸ¬ì™€ "í”„ë ˆì„ ì—†ìŒ"ì„ êµ¬ë¶„)
pub enum DecodeResult {
    /// ì •ìƒ í”„ë ˆì„
    Frame(Frame),
    /// í”„ë ˆì„ ìŠ¤í‚µë¨ (ë””ì½”ë”© ì‹¤íŒ¨í–ˆì§€ë§Œ ê³„ì† ê°€ëŠ¥, ì´ì „ í”„ë ˆì„ ìœ ì§€)
    FrameSkipped,
    /// EOF ë„ë‹¬ + ë§ˆì§€ë§‰ ì„±ê³µ í”„ë ˆì„ ë°˜í™˜
    EndOfStream(Frame),
    /// EOF ë„ë‹¬ + ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ ì—†ìŒ
    EndOfStreamEmpty,
}

/// ë¹„ë””ì˜¤ ë””ì½”ë” (ffmpeg-next, ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜)
pub struct Decoder {
    input_ctx: ffmpeg::format::context::Input,
    video_stream_index: usize,
    decoder: ffmpeg::codec::decoder::Video,
    scaler: ffmpeg::software::scaling::Context,
    width: u32,
    height: u32,
    fps: f64,
    duration_ms: i64,
    last_timestamp_ms: i64,
    is_hardware: bool,
    state: DecoderState,
    /// ë§ˆì§€ë§‰ ì„±ê³µ ë””ì½”ë”© í”„ë ˆì„ (EOF/ì—ëŸ¬ ì‹œ fallbackìš©)
    last_decoded_frame: Option<Frame>,
}

impl Decoder {
    /// Decoder ìƒì„± (Multi-threading ìµœì í™”)
    fn try_create_decoder(
        _codec_id: ffmpeg::codec::Id,
        codec_params: ffmpeg::codec::Parameters,
    ) -> Result<(ffmpeg::codec::decoder::Video, bool), String> {
        // Create decoder context
        let mut context = ffmpeg::codec::context::Context::from_parameters(codec_params)
            .map_err(|e| format!("Failed to create context: {}", e))?;

        // OPTIMIZATION: Multi-threading
        if let Ok(parallelism) = std::thread::available_parallelism() {
            let thread_count = parallelism.get();
            println!("   ğŸ”§ Enabling multi-threading: {} threads", thread_count);
            context.set_threading(ffmpeg::threading::Config {
                kind: ffmpeg::threading::Type::Frame,
                count: thread_count,
            });
        }

        // Open decoder
        let decoder = context
            .decoder()
            .video()
            .map_err(|e| format!("Failed to get video decoder: {}", e))?;

        // Hardware acceleration is set at input level (input_with_dictionary)
        // We'll detect it based on decoder format later
        Ok((decoder, false))  // is_hardware will be updated based on actual usage
    }

    /// ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
    pub fn open(file_path: &Path) -> Result<Self, String> {
        // FFmpeg ì´ˆê¸°í™”
        ffmpeg::init().map_err(|e| format!("FFmpeg init failed: {}", e))?;

        // ì†Œí”„íŠ¸ì›¨ì–´ ë””ì½”ë”© (ë©€í‹°ìŠ¤ë ˆë“œ Frame threadingìœ¼ë¡œ ì¶©ë¶„í•œ ì„±ëŠ¥)
        // NOTE: hwaccel=cuda ì˜µì…˜ì€ ì½˜ì†”/í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ hang ìœ ë°œí•˜ë¯€ë¡œ ì œê±°
        let input_ctx = ffmpeg::format::input(&file_path)
            .map_err(|e| format!("Failed to open file: {}", e))?;

        // ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì°¾ê¸°
        let video_stream = input_ctx
            .streams()
            .best(ffmpeg::media::Type::Video)
            .ok_or("No video stream found")?;

        let video_stream_index = video_stream.index();
        let codec_params = video_stream.parameters();
        let codec_id = codec_params.id();

        // OPTIMIZATION 2: Hardware acceleration ì‹œë„
        println!("ğŸ¬ Codec: {:?}", codec_id);

        let (decoder, is_hardware) = Self::try_create_decoder(codec_id, codec_params)?;

        // ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
        let src_width = decoder.width();
        let src_height = decoder.height();

        // OPTIMIZATION 1: ë””ì½”ë”© í•´ìƒë„ ì ˆë°˜ìœ¼ë¡œ ë‚®ì¶¤ (4ë°° ì†ë„ ê°œì„  ì˜ˆìƒ)
        let decode_width = 960;
        let decode_height = 540;

        println!("ğŸ¬ Decoder opened: {}x{} (source) -> {}x{} (decode target)",
                 src_width, src_height, decode_width, decode_height);

        // FPS ê³„ì‚°
        let fps = f64::from(video_stream.avg_frame_rate());

        // Duration ê³„ì‚° (ms)
        let duration_ms = if video_stream.duration() > 0 {
            let time_base = video_stream.time_base();
            (video_stream.duration() * i64::from(time_base.numerator()) * 1000)
                / i64::from(time_base.denominator())
        } else if input_ctx.duration() > 0 {
            input_ctx.duration() / 1000 // microseconds to milliseconds
        } else {
            0
        };

        // Scaler ìƒì„± (YUV -> RGBA ë³€í™˜ + í•´ìƒë„ ì¶•ì†Œ)
        // CRITICAL: outputì„ 960x540ìœ¼ë¡œ ì„¤ì • (1920x1080ì˜ 1/4 í”½ì…€)
        let scaler = ffmpeg::software::scaling::Context::get(
            decoder.format(),
            src_width,
            src_height,
            ffmpeg::format::Pixel::RGBA,
            decode_width,
            decode_height,
            ffmpeg::software::scaling::Flags::FAST_BILINEAR,  // BILINEAR -> FAST_BILINEAR (ë” ë¹ ë¦„)
        )
        .map_err(|e| format!("Failed to create scaler: {}", e))?;

        Ok(Self {
            input_ctx,
            video_stream_index,
            decoder,
            scaler,
            width: decode_width,
            height: decode_height,
            fps,
            duration_ms,
            last_timestamp_ms: -1,
            is_hardware,
            state: DecoderState::Ready,
            last_decoded_frame: None,
        })
    }

    /// ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    pub fn width(&self) -> u32 {
        self.width
    }

    pub fn height(&self) -> u32 {
        self.height
    }

    pub fn fps(&self) -> f64 {
        self.fps
    }

    pub fn duration_ms(&self) -> i64 {
        self.duration_ms
    }

    pub fn state(&self) -> DecoderState {
        self.state
    }

    /// íŠ¹ì • ì‹œê°„ì˜ í”„ë ˆì„ ë””ì½”ë”© (ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜)
    /// - ìˆœì°¨ ì¬ìƒ: seek ì—†ì´ ë‹¤ìŒ í”„ë ˆì„ ë””ì½”ë”© (ìµœì  ê²½ë¡œ)
    /// - ëœë¤ ì ‘ê·¼(ìŠ¤í¬ëŸ½): seek â†’ í‚¤í”„ë ˆì„ì—ì„œ ëª©í‘œ PTSê¹Œì§€ ë””ì½”ë”© ì „ì§„
    /// - EOF/ì—ëŸ¬: DecodeResultë¡œ êµ¬ë¶„í•˜ì—¬ ì¬ìƒ ì¤‘ë‹¨ ì—†ì´ ì•ˆì „ ì²˜ë¦¬
    pub fn decode_frame(&mut self, timestamp_ms: i64) -> Result<DecodeResult, String> {
        // Error ìƒíƒœì—ì„œëŠ” ë§ˆì§€ë§‰ í”„ë ˆì„ ë°˜í™˜
        if self.state == DecoderState::Error {
            return match &self.last_decoded_frame {
                Some(f) => Ok(DecodeResult::EndOfStream(f.clone())),
                None => Ok(DecodeResult::EndOfStreamEmpty),
            };
        }

        let frame_duration_ms = (1000.0 / self.fps).max(1.0) as i64;
        let is_sequential = self.state == DecoderState::Ready
            && timestamp_ms >= self.last_timestamp_ms
            && timestamp_ms <= self.last_timestamp_ms + frame_duration_ms * 2;

        // EOF ìƒíƒœì—ì„œ seek â†’ Readyë¡œ ë³µêµ¬
        if !is_sequential {
            if let Err(e) = self.seek(timestamp_ms) {
                eprintln!("Seek failed at {}ms: {}", timestamp_ms, e);
                // seek ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ í”„ë ˆì„ ë°˜í™˜ (ì¬ìƒ ì¤‘ë‹¨ ë°©ì§€)
                return match &self.last_decoded_frame {
                    Some(_) => Ok(DecodeResult::FrameSkipped),
                    None => Ok(DecodeResult::EndOfStreamEmpty),
                };
            }
        }

        self.last_timestamp_ms = timestamp_ms;

        // Seek í›„: ëª©í‘œ PTSê¹Œì§€ ë””ì½”ë”© ì „ì§„ì— í•„ìš”í•œ ì •ë³´ ê³„ì‚°
        let target_info = if !is_sequential {
            let stream = self.input_ctx.stream(self.video_stream_index)
                .ok_or("Video stream not found")?;
            let tb = stream.time_base();
            let target_pts = (timestamp_ms * i64::from(tb.denominator()))
                / (i64::from(tb.numerator()) * 1000);
            let tolerance_pts = (frame_duration_ms * i64::from(tb.denominator()))
                / (i64::from(tb.numerator()) * 1000);
            Some((target_pts, tolerance_pts))
        } else {
            None // ìˆœì°¨ ì¬ìƒ: PTS í™•ì¸ ë¶ˆí•„ìš”, ë‹¤ìŒ í”„ë ˆì„ ì¦‰ì‹œ ë°˜í™˜
        };

        let mut decoded_frame: Option<ffmpeg::frame::Video> = None;

        // Step 1: ë””ì½”ë” ë²„í¼ì—ì„œ í”„ë ˆì„ í™•ì¸
        loop {
            let mut frame = ffmpeg::frame::Video::empty();
            if self.decoder.receive_frame(&mut frame).is_err() {
                break;
            }
            if is_pts_at_target(target_info, &frame) {
                decoded_frame = Some(frame);
                break;
            }
        }

        // Step 2: íŒ¨í‚· ì½ìœ¼ë©° ë””ì½”ë”© (ëª©í‘œ PTS ë„ë‹¬ê¹Œì§€)
        let mut hit_eof = false;
        if decoded_frame.is_none() {
            let mut packet_count = 0;
            let mut packets_exhausted = true; // for ë£¨í”„ê°€ ëê¹Œì§€ ì†Œì§„ë˜ë©´ EOF

            for (stream, packet) in self.input_ctx.packets() {
                if stream.index() != self.video_stream_index {
                    continue;
                }

                // send_packet (EAGAIN ì‹œ drain í›„ ì¬ì‹œë„)
                if self.decoder.send_packet(&packet).is_err() {
                    loop {
                        let mut frame = ffmpeg::frame::Video::empty();
                        if self.decoder.receive_frame(&mut frame).is_err() { break; }
                        if is_pts_at_target(target_info, &frame) {
                            decoded_frame = Some(frame);
                            break;
                        }
                    }
                    if decoded_frame.is_some() { packets_exhausted = false; break; }
                    let _ = self.decoder.send_packet(&packet);
                }

                // ë””ì½”ë”©ëœ í”„ë ˆì„ ìˆ˜ì‹  (B-frame ì¬ì •ë ¬ ëŒ€ì‘)
                loop {
                    let mut frame = ffmpeg::frame::Video::empty();
                    if self.decoder.receive_frame(&mut frame).is_err() { break; }
                    if is_pts_at_target(target_info, &frame) {
                        decoded_frame = Some(frame);
                        break;
                    }
                }

                if decoded_frame.is_some() { packets_exhausted = false; break; }

                packet_count += 1;
                if packet_count > 300 {
                    // ì•ˆì „ì¥ì¹˜: 300íŒ¨í‚· ì†Œì§„ â†’ FrameSkipped (ì—ëŸ¬ê°€ ì•„ë‹˜)
                    packets_exhausted = false;
                    break;
                }
            }

            // for ë£¨í”„ê°€ ìì—°ì¢…ë£Œ = íŒ¨í‚· ì†Œì§„ = EOF
            if packets_exhausted && decoded_frame.is_none() {
                hit_eof = true;
            }
        }

        // EOF ì²˜ë¦¬
        if hit_eof {
            self.state = DecoderState::EndOfStream;
            return match &self.last_decoded_frame {
                Some(f) => Ok(DecodeResult::EndOfStream(f.clone())),
                None => Ok(DecodeResult::EndOfStreamEmpty),
            };
        }

        // í”„ë ˆì„ ë””ì½”ë”© ì‹¤íŒ¨ (EOFê°€ ì•„ë‹Œ ê²½ìš°) â†’ FrameSkipped
        let raw_frame = match decoded_frame {
            Some(f) => f,
            None => return Ok(DecodeResult::FrameSkipped),
        };

        // RGBA í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        let frame = self.convert_to_rgba(&raw_frame, timestamp_ms)?;

        // ë§ˆì§€ë§‰ ì„±ê³µ í”„ë ˆì„ ì €ì¥ (EOF/ì—ëŸ¬ ì‹œ fallback)
        self.last_decoded_frame = Some(frame.clone());
        self.state = DecoderState::Ready;

        Ok(DecodeResult::Frame(frame))
    }

    /// ë””ì½”ë”©ëœ ffmpeg Video í”„ë ˆì„ì„ RGBA Frameìœ¼ë¡œ ë³€í™˜
    fn convert_to_rgba(&mut self, raw_frame: &ffmpeg::frame::Video, timestamp_ms: i64) -> Result<Frame, String> {
        let mut rgb_frame = ffmpeg::frame::Video::empty();
        self.scaler.run(raw_frame, &mut rgb_frame)
            .map_err(|e| format!("Failed to scale frame: {}", e))?;

        let size = (self.width * self.height * 4) as usize;
        let mut data = vec![0u8; size];

        let src_data = rgb_frame.data(0);
        let linesize = rgb_frame.stride(0);

        for y in 0..self.height as usize {
            let src_offset = y * linesize;
            let dst_offset = y * (self.width as usize * 4);
            let row_size = self.width as usize * 4;

            data[dst_offset..dst_offset + row_size]
                .copy_from_slice(&src_data[src_offset..src_offset + row_size]);
        }

        Ok(Frame {
            width: self.width,
            height: self.height,
            format: PixelFormat::RGBA,
            data,
            timestamp_ms,
        })
    }

    /// ë‹¤ìŒ í”„ë ˆì„ ë””ì½”ë”©
    pub fn decode_next_frame(&mut self) -> Result<Option<Frame>, String> {
        // TODO: êµ¬í˜„
        Ok(None)
    }

    /// ì¸ë„¤ì¼ í”„ë ˆì„ ìƒì„± (ì‘ì€ í•´ìƒë„ë¡œ ë””ì½”ë”©)
    pub fn generate_thumbnail(&mut self, timestamp_ms: i64, thumb_width: u32, thumb_height: u32) -> Result<Frame, String> {
        println!("ğŸ“¸ Generating thumbnail: timestamp={}ms, size={}x{}", timestamp_ms, thumb_width, thumb_height);

        // seek to timestamp
        self.seek(timestamp_ms)?;

        // íŒ¨í‚· ì½ê³  ë””ì½”ë”©
        let mut decoded_frame: Option<ffmpeg::frame::Video> = None;

        for (stream, packet) in self.input_ctx.packets() {
            if stream.index() == self.video_stream_index {
                self.decoder.send_packet(&packet)
                    .map_err(|e| format!("Failed to send packet: {}", e))?;

                let mut frame = ffmpeg::frame::Video::empty();
                if self.decoder.receive_frame(&mut frame).is_ok() {
                    decoded_frame = Some(frame);
                    break;
                }
            }
        }

        let frame = decoded_frame.ok_or("Failed to decode thumbnail frame")?;

        // ì¸ë„¤ì¼ìš© scaler ìƒì„± (ì‘ì€ í•´ìƒë„)
        let mut thumb_scaler = ffmpeg::software::scaling::Context::get(
            self.decoder.format(),
            self.decoder.width(),
            self.decoder.height(),
            ffmpeg::format::Pixel::RGBA,
            thumb_width,
            thumb_height,
            ffmpeg::software::scaling::Flags::FAST_BILINEAR,
        )
        .map_err(|e| format!("Failed to create thumbnail scaler: {}", e))?;

        // RGBA í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        let mut rgb_frame = ffmpeg::frame::Video::empty();
        thumb_scaler.run(&frame, &mut rgb_frame)
            .map_err(|e| format!("Failed to scale thumbnail: {}", e))?;

        // í”„ë ˆì„ ë°ì´í„° ë³µì‚¬
        let size = (thumb_width * thumb_height * 4) as usize;
        let mut data = vec![0u8; size];

        let src_data = rgb_frame.data(0);
        let linesize = rgb_frame.stride(0);

        for y in 0..thumb_height as usize {
            let src_offset = y * linesize;
            let dst_offset = y * (thumb_width as usize * 4);
            let row_size = thumb_width as usize * 4;

            data[dst_offset..dst_offset + row_size]
                .copy_from_slice(&src_data[src_offset..src_offset + row_size]);
        }

        println!("âœ… Thumbnail generated: {}x{}, data size={}", thumb_width, thumb_height, data.len());

        Ok(Frame {
            width: thumb_width,
            height: thumb_height,
            format: PixelFormat::RGBA,
            data,
            timestamp_ms,
        })
    }

    /// íŠ¹ì • ì‹œê°„ìœ¼ë¡œ seek (EOF/Error ìƒíƒœì—ì„œ ìë™ ë³µêµ¬)
    pub fn seek(&mut self, timestamp_ms: i64) -> Result<(), String> {
        let stream = self.input_ctx.stream(self.video_stream_index)
            .ok_or("Video stream not found")?;

        let time_base = stream.time_base();

        // milliseconds to stream time base
        let timestamp = (timestamp_ms * i64::from(time_base.denominator()))
            / (i64::from(time_base.numerator()) * 1000);

        match self.input_ctx.seek(timestamp, ..timestamp) {
            Ok(_) => {
                self.decoder.flush();
                // seek ì„±ê³µ â†’ Ready ìƒíƒœë¡œ ë³µêµ¬ (EOF/Errorì—ì„œ ë³µêµ¬)
                self.state = DecoderState::Ready;
                Ok(())
            }
            Err(e) => {
                // seek ì‹¤íŒ¨ â†’ flush í›„ ì¬ì‹œë„ 1íšŒ
                self.decoder.flush();
                match self.input_ctx.seek(timestamp, ..timestamp) {
                    Ok(_) => {
                        self.decoder.flush();
                        self.state = DecoderState::Ready;
                        Ok(())
                    }
                    Err(_) => {
                        self.state = DecoderState::Error;
                        Err(format!("Seek failed after retry: {}", e))
                    }
                }
            }
        }
    }
}

/// PTSê°€ ëª©í‘œì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸ (ëª¨ë“ˆ ë ˆë²¨ í•¨ìˆ˜ - borrow checker ì¶©ëŒ ë°©ì§€)
/// target_info: Noneì´ë©´ ìˆœì°¨ ì¬ìƒ â†’ í•­ìƒ true (ì²« í”„ë ˆì„ ì¦‰ì‹œ ìˆ˜ë½)
/// target_info: Some((target_pts, tolerance_pts)) â†’ PTS >= target - tolerance ì´ë©´ true
fn is_pts_at_target(target_info: Option<(i64, i64)>, frame: &ffmpeg::frame::Video) -> bool {
    match target_info {
        None => true, // ìˆœì°¨ ì¬ìƒ: ë‹¤ìŒ í”„ë ˆì„ ë¬´ì¡°ê±´ ì‚¬ìš©
        Some((target_pts, tolerance_pts)) => {
            match frame.pts() {
                Some(pts) => pts >= target_pts - tolerance_pts,
                None => true, // PTS ì •ë³´ ì—†ìœ¼ë©´ ìˆ˜ë½
            }
        }
    }
}

// ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•˜ë¯€ë¡œ í…ŒìŠ¤íŠ¸ëŠ” ì£¼ì„ ì²˜ë¦¬
#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;

    #[test]
    #[ignore] // ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ í•„ìš”
    fn test_decoder_open() {
        let path = PathBuf::from("test.mp4");
        let decoder = Decoder::open(&path);
        assert!(decoder.is_ok());
    }

    #[test]
    #[ignore] // ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ í•„ìš”
    fn test_decode_frame() {
        let path = PathBuf::from("test.mp4");
        let mut decoder = Decoder::open(&path).unwrap();

        let frame = decoder.decode_frame(1000);
        assert!(frame.is_ok());

        let frame = frame.unwrap();
        assert_eq!(frame.timestamp_ms, 1000);
        assert!(!frame.data.is_empty());
    }

    #[test]
    fn test_decoder_with_real_file() {
        // ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
        let path = PathBuf::from(r"C:\Users\USER\Videos\ë“œë¡  ëŒ€ì‘ 2.75ì¸ì¹˜ ë¡œì¼“ 'ë¹„ê¶'ìœ¼ë¡œ ìœ ë„í‚¤íŠ¸ ê°œë°œ, ì‚¬ìš°ë”” ê¸°ìˆ í˜‘ë ¥ ì¶”ì§„.mp4");

        if !path.exists() {
            println!("âš ï¸ Test video file not found, skipping test");
            return;
        }

        println!("\n=== Decoder Test ===");
        println!("ğŸ“¹ Opening video: {:?}", path);

        // 1. ë””ì½”ë” ì—´ê¸°
        let mut decoder = match Decoder::open(&path) {
            Ok(d) => {
                println!("âœ… Decoder opened successfully");
                println!("   Resolution: {}x{}", d.width(), d.height());
                println!("   FPS: {:.2}", d.fps());
                println!("   Duration: {}ms", d.duration_ms());
                d
            }
            Err(e) => {
                panic!("âŒ Failed to open decoder: {}", e);
            }
        };

        // 2. í”„ë ˆì„ ë””ì½”ë”© í…ŒìŠ¤íŠ¸ (0ms, 1000ms, 2000ms)
        let timestamps = [0i64, 1000, 2000];
        for timestamp in timestamps {
            println!("\nğŸ¬ Decoding frame at {}ms...", timestamp);
            match decoder.decode_frame(timestamp) {
                Ok(frame) => {
                    println!("   âœ… Frame decoded: {}x{}", frame.width, frame.height);
                    println!("   Data size: {} bytes", frame.data.len());

                    // ì²« 10í”½ì…€ í™•ì¸
                    let pixels: Vec<u8> = frame.data.iter().take(40).copied().collect();
                    println!("   First 10 pixels (RGBA): {:?}", pixels);

                    // ê²€ì¦
                    assert_eq!(frame.width, decoder.width());
                    assert_eq!(frame.height, decoder.height());
                    assert_eq!(frame.data.len(), (frame.width * frame.height * 4) as usize);
                    assert_eq!(frame.format, PixelFormat::RGBA);
                }
                Err(e) => {
                    panic!("âŒ Failed to decode frame at {}ms: {}", timestamp, e);
                }
            }
        }

        println!("\nâœ… All decoder tests passed!");
    }
}
