// FFmpeg Decoder ëª¨ë“ˆ (ffmpeg-next with hardware acceleration)
// ì•„í‚¤í…ì²˜: ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜ ë””ì½”ë” + EOF/ì—ëŸ¬ ì•ˆì „ ì²˜ë¦¬

use ffmpeg_next as ffmpeg;
use std::path::Path;

/// ë¹„ë””ì˜¤ í”„ë ˆì„ ë°ì´í„°
#[derive(Debug, Clone)]
pub struct Frame {
    pub width: u32,
    pub height: u32,
    pub format: PixelFormat,
    pub data: Vec<u8>,
    pub timestamp_ms: i64,
}

/// í”½ì…€ í¬ë§·
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PixelFormat {
    RGBA,
    RGB,
    YUV420P,
}

/// ë””ì½”ë” ìƒíƒœ ë¨¸ì‹ 
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum DecoderState {
    Ready,          // ì •ìƒ ë™ì‘ ê°€ëŠ¥
    EndOfStream,    // íŒŒì¼ ë ë„ë‹¬ (seekìœ¼ë¡œ ë³µêµ¬ ê°€ëŠ¥)
    Error,          // ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬
}

/// ë””ì½”ë”© ê²°ê³¼ (ì—ëŸ¬ì™€ "í”„ë ˆì„ ì—†ìŒ"ì„ êµ¬ë¶„)
pub enum DecodeResult {
    /// ì •ìƒ í”„ë ˆì„
    Frame(Frame),
    /// í”„ë ˆì„ ìŠ¤í‚µë¨ (ë””ì½”ë”© ì‹¤íŒ¨í–ˆì§€ë§Œ ê³„ì† ê°€ëŠ¥, ì´ì „ í”„ë ˆì„ ìœ ì§€)
    FrameSkipped,
    /// EOF ë„ë‹¬ + ë§ˆì§€ë§‰ ì„±ê³µ í”„ë ˆì„ ë°˜í™˜
    EndOfStream(Frame),
    /// EOF ë„ë‹¬ + ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ ì—†ìŒ
    EndOfStreamEmpty,
}

/// ë¹„ë””ì˜¤ ë””ì½”ë” (ffmpeg-next, ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜)
pub struct Decoder {
    input_ctx: ffmpeg::format::context::Input,
    video_stream_index: usize,
    decoder: ffmpeg::codec::decoder::Video,
    scaler: ffmpeg::software::scaling::Context,
    width: u32,
    height: u32,
    fps: f64,
    duration_ms: i64,
    last_timestamp_ms: i64,
    is_hardware: bool,
    state: DecoderState,
    /// ë§ˆì§€ë§‰ ì„±ê³µ ë””ì½”ë”© í”„ë ˆì„ (EOF/ì—ëŸ¬ ì‹œ fallbackìš©)
    last_decoded_frame: Option<Frame>,
    /// Forward decode ì„ê³„ê°’ (ms)
    /// - ê¸°ë³¸ê°’: frame_duration * 2 (í”„ë¦¬ë·° ì¬ìƒìš©)
    /// - ì¸ë„¤ì¼ ì„¸ì…˜: 10000ms (GOP ë‚´ ë¶ˆí•„ìš”í•œ seek ë°©ì§€)
    /// - í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì´ ë²”ìœ„ ë‚´ì˜ ë¯¸ë˜ timestampëŠ” seek ì—†ì´ forward decode
    forward_threshold_ms: i64,
    /// EOFê°€ ë°œìƒí•œ timestamp (ms) â€” ì´ ì´í›„ timestampì— ëŒ€í•´ seek+decode ë°˜ë³µ ë°©ì§€
    /// ì—­ë°©í–¥ seek ì‹œ ìë™ ì´ˆê¸°í™”
    eof_timestamp_ms: Option<i64>,
    /// Exportìš© YUV420P ì§ì ‘ ì¶œë ¥ ëª¨ë“œ (RGBA ë³€í™˜ ê±´ë„ˆëœ€)
    /// true: ë””ì½”ë” â†’ YUV420P â†’ ì¸ì½”ë” (ìƒ‰ê³µê°„ ë³€í™˜ ì—†ì´ ìµœê³  í’ˆì§ˆ)
    /// false: ë””ì½”ë” â†’ RGBA â†’ í”„ë¦¬ë·°/ì¸ë„¤ì¼/ì¸ì½”ë”
    yuv_output: bool,
}

impl Decoder {
    /// Decoder ìƒì„± (Multi-threading ìµœì í™”)
    fn try_create_decoder(
        _codec_id: ffmpeg::codec::Id,
        codec_params: ffmpeg::codec::Parameters,
    ) -> Result<(ffmpeg::codec::decoder::Video, bool), String> {
        // Create decoder context
        let mut context = ffmpeg::codec::context::Context::from_parameters(codec_params)
            .map_err(|e| format!("Failed to create context: {}", e))?;

        // OPTIMIZATION: Multi-threading (ë””ì½”ë”ë‹¹ ìµœëŒ€ 4ìŠ¤ë ˆë“œ)
        // 960x540ì—ì„œ 4ìŠ¤ë ˆë“œ ì´ìƒì€ ìˆ˜í™•ì²´ê°. íŠ¸ëœì§€ì…˜ ì‹œ 2ê°œ ë””ì½”ë” ë™ì‹œ êµ¬ë™ â†’
        // ì „ì²´ ì½”ì–´(8~16) ì‚¬ìš©í•˜ë©´ ìŠ¤ë ˆë“œ ê²½í•©ìœ¼ë¡œ ì˜¤íˆë ¤ ëŠë ¤ì§
        if let Ok(parallelism) = std::thread::available_parallelism() {
            let thread_count = parallelism.get().min(4);
            context.set_threading(ffmpeg::threading::Config {
                kind: ffmpeg::threading::Type::Frame,
                count: thread_count,
            });
        }

        // Open decoder
        let decoder = context
            .decoder()
            .video()
            .map_err(|e| format!("Failed to get video decoder: {}", e))?;

        // Hardware acceleration is set at input level (input_with_dictionary)
        // We'll detect it based on decoder format later
        Ok((decoder, false))  // is_hardware will be updated based on actual usage
    }

    /// ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸° (í”„ë¦¬ë·°ìš© 960x540 ê³ ì • í•´ìƒë„)
    pub fn open(file_path: &Path) -> Result<Self, String> {
        Self::open_internal(file_path, 960, 540, false, false)
    }

    /// ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸° (ì»¤ìŠ¤í…€ ì¶œë ¥ í•´ìƒë„ ì§€ì •)
    /// ì¸ë„¤ì¼ ì„¸ì…˜ì—ì„œëŠ” ì§ì ‘ ì¸ë„¤ì¼ í¬ê¸°ë¡œ ë””ì½”ë”©í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë‹¤ìš´ìŠ¤ì¼€ì¼ ë°©ì§€
    pub fn open_with_resolution(file_path: &Path, target_width: u32, target_height: u32) -> Result<Self, String> {
        Self::open_internal(file_path, target_width, target_height, false, false)
    }

    /// Exportìš© ê³ í’ˆì§ˆ ë””ì½”ë” (YUV420P ì§ì ‘ ì¶œë ¥ + LANCZOS ë¦¬ì‚¬ì´ì¦ˆ)
    /// RGBA ë³€í™˜ì„ ê±´ë„ˆë›°ì–´ ìƒ‰ê³µê°„ ë³€í™˜ ì†ì‹¤ ì œê±°
    pub fn open_for_export(file_path: &Path, target_width: u32, target_height: u32) -> Result<Self, String> {
        Self::open_internal(file_path, target_width, target_height, true, true)
    }

    /// ë‚´ë¶€ ë””ì½”ë” ìƒì„±
    /// - high_quality: LANCZOS(Export) vs FAST_BILINEAR(í”„ë¦¬ë·°)
    /// - yuv_output: YUV420P ì§ì ‘ ì¶œë ¥(Export) vs RGBA(í”„ë¦¬ë·°)
    fn open_internal(file_path: &Path, target_width: u32, target_height: u32, high_quality: bool, yuv_output: bool) -> Result<Self, String> {
        ffmpeg::init().map_err(|e| format!("FFmpeg init failed: {}", e))?;

        // 1ì°¨ ì‹œë„: ê¸°ë³¸ ì˜¤í”ˆ
        // 2ì°¨ ì‹œë„: moov atomì´ íŒŒì¼ ëì— ìˆëŠ” ê²½ìš° (ì¹´ë©”ë¼ ë…¹í™”ë³¸ ë“±) â€” probesize í™•ì¥
        let input_ctx = ffmpeg::format::input(&file_path)
            .or_else(|_| {
                let mut opts = ffmpeg::Dictionary::new();
                opts.set("probesize", "100000000");   // 100MB
                opts.set("analyzeduration", "30000000"); // 30ì´ˆ
                ffmpeg::format::input_with_dictionary(&file_path, opts)
            })
            .map_err(|e| format!("Failed to open file: {}", e))?;

        let video_stream = input_ctx
            .streams()
            .best(ffmpeg::media::Type::Video)
            .ok_or("No video stream found")?;

        let video_stream_index = video_stream.index();
        let codec_params = video_stream.parameters();
        let codec_id = codec_params.id();

        let (decoder, is_hardware) = Self::try_create_decoder(codec_id, codec_params)?;

        let src_width = decoder.width();
        let src_height = decoder.height();

        let decode_width = target_width;
        let decode_height = target_height;

        let fps = f64::from(video_stream.avg_frame_rate());

        let duration_ms = if video_stream.duration() > 0 {
            let time_base = video_stream.time_base();
            (video_stream.duration() * i64::from(time_base.numerator()) * 1000)
                / i64::from(time_base.denominator())
        } else if input_ctx.duration() > 0 {
            input_ctx.duration() / 1000
        } else {
            0
        };

        // Export: LANCZOS (ìµœê³  í’ˆì§ˆ), í”„ë¦¬ë·°: FAST_BILINEAR (ì†ë„ ìš°ì„ )
        let scaler_flags = if high_quality {
            ffmpeg::software::scaling::Flags::LANCZOS
        } else {
            ffmpeg::software::scaling::Flags::FAST_BILINEAR
        };

        // YUV ì§ì ‘ ì¶œë ¥: ìƒ‰ê³µê°„ ë³€í™˜ ì—†ì´ YUV420Pë¡œ ë¦¬ì‚¬ì´ì¦ˆë§Œ
        // RGBA ì¶œë ¥: í”„ë¦¬ë·°/ì¸ë„¤ì¼ìš© ìƒ‰ê³µê°„ ë³€í™˜
        let output_pixel_format = if yuv_output {
            ffmpeg::format::Pixel::YUV420P
        } else {
            ffmpeg::format::Pixel::RGBA
        };

        let scaler = ffmpeg::software::scaling::Context::get(
            decoder.format(),
            src_width,
            src_height,
            output_pixel_format,
            decode_width,
            decode_height,
            scaler_flags,
        )
        .map_err(|e| format!("Failed to create scaler: {}", e))?;

        let _frame_duration_ms = (1000.0 / fps).max(1.0) as i64;

        Ok(Self {
            input_ctx,
            video_stream_index,
            decoder,
            scaler,
            width: decode_width,
            height: decode_height,
            fps,
            duration_ms,
            last_timestamp_ms: -1,
            is_hardware,
            state: DecoderState::Ready,
            last_decoded_frame: None,
            // [ë¡¤ë°±] ìŠ¤í¬ëŸ½ ë°˜ì‘ì„±ì„ ìœ„í•´ ê¸°ë³¸ê°’ì€ ë‚®ê²Œ ìœ ì§€ (100ms)
            // ì¬ìƒ ì‹œ í”„ë¦¬ì¦ˆ ë°©ì§€ëŠ” set_playback_mode()ë¥¼ í†µí•´ ë™ì ìœ¼ë¡œ ê°’ì„ ì˜¬ë ¤ì•¼ í•¨
            forward_threshold_ms: 100,
            eof_timestamp_ms: None,
            yuv_output,
        })
    }

    /// Forward decode ì„ê³„ê°’ ì„¤ì •
    /// ì¸ë„¤ì¼ ì„¸ì…˜ì—ì„œ í˜¸ì¶œí•˜ì—¬ GOP ë‚´ ë¶ˆí•„ìš”í•œ seek ë°©ì§€
    pub fn set_forward_threshold(&mut self, threshold_ms: i64) {
        self.forward_threshold_ms = threshold_ms;
    }

    /// ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    pub fn width(&self) -> u32 {
        self.width
    }

    pub fn height(&self) -> u32 {
        self.height
    }

    pub fn fps(&self) -> f64 {
        self.fps
    }

    pub fn duration_ms(&self) -> i64 {
        self.duration_ms
    }

    pub fn state(&self) -> DecoderState {
        self.state
    }

    /// íŠ¹ì • ì‹œê°„ì˜ í”„ë ˆì„ ë””ì½”ë”© (ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜)
    /// - ì¦‰ì‹œ ìˆœì°¨ (1í”„ë ˆì„ ì´ë‚´): seek ì—†ì´, PTS í™•ì¸ ì—†ì´ ë‹¤ìŒ í”„ë ˆì„ ë°˜í™˜
    /// - Forward decode (threshold ì´ë‚´): seek ì—†ì´, PTS í™•ì¸í•˜ë©° ì „ì§„
    /// - ëœë¤ ì ‘ê·¼ (threshold ì´ˆê³¼ ë˜ëŠ” ì—­ë°©í–¥): seek + PTS í™•ì¸
    /// - EOF/ì—ëŸ¬: DecodeResultë¡œ êµ¬ë¶„í•˜ì—¬ ì•ˆì „ ì²˜ë¦¬
    pub fn decode_frame(&mut self, timestamp_ms: i64) -> Result<DecodeResult, String> {
        // Error ìƒíƒœì—ì„œëŠ” ë§ˆì§€ë§‰ í”„ë ˆì„ ë°˜í™˜
        if self.state == DecoderState::Error {
            return match &self.last_decoded_frame {
                Some(f) => Ok(DecodeResult::EndOfStream(f.clone())),
                None => Ok(DecodeResult::EndOfStreamEmpty),
            };
        }

        // EOF ìºì‹±: ì´ë¯¸ EOFì— ë„ë‹¬í•œ ìœ„ì¹˜ ì´í›„ì˜ timestampëŠ” ì¦‰ì‹œ ë°˜í™˜
        // (seek â†’ ì „ì²´ íŒ¨í‚· ì½ê¸° â†’ ë‹¤ì‹œ EOF ë°˜ë³µ ë°©ì§€)
        if let Some(eof_ts) = self.eof_timestamp_ms {
            if timestamp_ms >= eof_ts {
                return match &self.last_decoded_frame {
                    Some(f) => Ok(DecodeResult::EndOfStream(f.clone())),
                    None => Ok(DecodeResult::EndOfStreamEmpty),
                };
            } else {
                // ì—­ë°©í–¥ seek ì‹œ EOF ë§ˆì»¤ ì´ˆê¸°í™”
                self.eof_timestamp_ms = None;
            }
        }

        let frame_duration_ms = (1000.0 / self.fps).max(1.0) as i64;

        // 3ë‹¨ê³„ íŒì •: ì¦‰ì‹œìˆœì°¨ / forward decode / ëœë¤ì ‘ê·¼
        let is_ahead = self.state == DecoderState::Ready
            && timestamp_ms >= self.last_timestamp_ms;
        let gap_ms = timestamp_ms - self.last_timestamp_ms;

        // ì¦‰ì‹œ ìˆœì°¨: ë‹¤ìŒ í”„ë ˆì„ (1í”„ë ˆì„ ì´ë‚´ ì°¨ì´)
        let is_immediate = is_ahead && gap_ms <= frame_duration_ms * 2;
        // Forward decode: threshold ì´ë‚´ ì „ì§„ (seek ë¶ˆí•„ìš”, PTS í™•ì¸ í•„ìš”)
        let is_forward = is_ahead && !is_immediate && gap_ms <= self.forward_threshold_ms;
        // ê·¸ ì™¸: ëœë¤ ì ‘ê·¼ (seek í•„ìš”)
        let needs_seek = !is_immediate && !is_forward;

        if needs_seek {
            if let Err(e) = self.seek(timestamp_ms) {
                eprintln!("Seek failed at {}ms: {}", timestamp_ms, e);
                return match &self.last_decoded_frame {
                    Some(_) => Ok(DecodeResult::FrameSkipped),
                    None => Ok(DecodeResult::EndOfStreamEmpty),
                };
            }
        }

        self.last_timestamp_ms = timestamp_ms;

        // PTS í™•ì¸ ì—¬ë¶€ ê²°ì •:
        // - ì¦‰ì‹œ ìˆœì°¨: PTS í™•ì¸ ë¶ˆí•„ìš” (ë‹¤ìŒ í”„ë ˆì„ ì¦‰ì‹œ ë°˜í™˜)
        // - Forward decode: PTS í™•ì¸ í•„ìš” (ëª©í‘œ ì‹œê°„ê¹Œì§€ ì „ì§„)
        // - ëœë¤ ì ‘ê·¼: PTS í™•ì¸ í•„ìš” (í‚¤í”„ë ˆì„ì—ì„œ ëª©í‘œê¹Œì§€ ì „ì§„)
        let target_info = if is_immediate {
            None
        } else {
            let stream = self.input_ctx.stream(self.video_stream_index)
                .ok_or("Video stream not found")?;
            let tb = stream.time_base();
            let target_pts = (timestamp_ms * i64::from(tb.denominator()))
                / (i64::from(tb.numerator()) * 1000);
            let tolerance_pts = (frame_duration_ms * i64::from(tb.denominator()))
                / (i64::from(tb.numerator()) * 1000);
            Some((target_pts, tolerance_pts))
        };

        let mut decoded_frame: Option<ffmpeg::frame::Video> = None;

        // Step 1: ë””ì½”ë” ë²„í¼ì—ì„œ í”„ë ˆì„ í™•ì¸
        loop {
            let mut frame = ffmpeg::frame::Video::empty();
            if self.decoder.receive_frame(&mut frame).is_err() {
                break;
            }
            if is_pts_at_target(target_info, &frame) {
                decoded_frame = Some(frame);
                break;
            }
        }

        // Step 2: íŒ¨í‚· ì½ìœ¼ë©° ë””ì½”ë”© (ëª©í‘œ PTS ë„ë‹¬ê¹Œì§€)
        let mut hit_eof = false;
        // [FIX] ëª©í‘œ PTSì— ë„ë‹¬í•˜ì§€ ëª»í•˜ê³  EOFê°€ ë°œìƒí•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´
        // íƒìƒ‰ ê³¼ì •ì—ì„œ ë³¸ ê°€ì¥ ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ì €ì¥
        let mut latest_seen_frame: Option<ffmpeg::frame::Video> = None;

        if decoded_frame.is_none() {
            let mut packet_count = 0;
            let mut packets_exhausted = true; // for ë£¨í”„ê°€ ëê¹Œì§€ ì†Œì§„ë˜ë©´ EOF

            for (stream, packet) in self.input_ctx.packets() {
                if stream.index() != self.video_stream_index {
                    continue;
                }

                // send_packet (EAGAIN ì‹œ drain í›„ ì¬ì‹œë„)
                if self.decoder.send_packet(&packet).is_err() {
                    loop {
                        let mut frame = ffmpeg::frame::Video::empty();
                        if self.decoder.receive_frame(&mut frame).is_err() { break; }
                        if is_pts_at_target(target_info, &frame) {
                            decoded_frame = Some(frame);
                            break;
                        }
                    }
                    if decoded_frame.is_some() { packets_exhausted = false; break; }
                    let _ = self.decoder.send_packet(&packet);
                }

                // ë””ì½”ë”©ëœ í”„ë ˆì„ ìˆ˜ì‹  (B-frame ì¬ì •ë ¬ ëŒ€ì‘)
                loop {
                    let mut frame = ffmpeg::frame::Video::empty();
                    if self.decoder.receive_frame(&mut frame).is_err() { break; }
                    if is_pts_at_target(target_info, &frame) {
                        decoded_frame = Some(frame);
                        break;
                    }
                    
                    // ëª©í‘œëŠ” ì•„ë‹ˆì§€ë§Œ ìœ íš¨í•œ í”„ë ˆì„ì´ë¯€ë¡œ ë³´ê´€ (Proxy ë¶ˆì¼ì¹˜ ëŒ€ì‘)
                    latest_seen_frame = Some(frame);
                }

                if decoded_frame.is_some() { packets_exhausted = false; break; }

                packet_count += 1;
                if packet_count > 3000 {
                    // ì•ˆì „ì¥ì¹˜: 3000íŒ¨í‚· ì†Œì§„ â†’ FrameSkipped (ì—ëŸ¬ê°€ ì•„ë‹˜)
                    // (íƒ€ì„ë¼ì¸ ì¸ë„¤ì¼ ìƒì„± ë“± ëœë¤ ì ‘ê·¼ ì‹œ ê¸´ GOPì—ì„œë„
                    // ë” ë¨¼ ìœ„ì¹˜ê¹Œì§€ íƒìƒ‰í•  ìˆ˜ ìˆë„ë¡ ìƒí•œì„ ìƒí–¥ ì¡°ì •)
                    packets_exhausted = false;
                    break;
                }
            }

            // for ë£¨í”„ê°€ ìì—°ì¢…ë£Œ = íŒ¨í‚· ì†Œì§„ = EOF
            if packets_exhausted && decoded_frame.is_none() {
                hit_eof = true;
            }
        }

        // EOF ì²˜ë¦¬
        if hit_eof {
            self.state = DecoderState::EndOfStream;
            // EOF ìœ„ì¹˜ ê¸°ë¡ â†’ ì´í›„ ê°™ì€/ë” ë¨¼ timestampì—ì„œ seek+ì „íŒ¨í‚·ì½ê¸° ë°˜ë³µ ë°©ì§€
            self.eof_timestamp_ms = Some(timestamp_ms);

            // [FIX] ëª©í‘œ í”„ë ˆì„ì„ ëª» ì°¾ì•˜ì§€ë§Œ íƒìƒ‰ ì¤‘ ë°œê²¬í•œ í”„ë ˆì„ì´ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ë°˜í™˜
            // (ì˜ˆ: Proxyê°€ ì›ë³¸ë³´ë‹¤ ì§§ì„ ë•Œ, Proxyì˜ ë í”„ë ˆì„ì„ ë³´ì—¬ì¤Œ)
            if let Some(raw_frame) = latest_seen_frame {
                if let Ok(frame) = self.convert_frame(&raw_frame, timestamp_ms) {
                    self.last_decoded_frame = Some(frame.clone());
                    return Ok(DecodeResult::EndOfStream(frame));
                }
            }

            return match &self.last_decoded_frame {
                Some(f) => Ok(DecodeResult::EndOfStream(f.clone())),
                None => Ok(DecodeResult::EndOfStreamEmpty),
            };
        }

        // í”„ë ˆì„ ë””ì½”ë”© ì‹¤íŒ¨ (EOFê°€ ì•„ë‹Œ ê²½ìš°) â†’ FrameSkipped
        let raw_frame = match decoded_frame {
            Some(f) => f,
            None => return Ok(DecodeResult::FrameSkipped),
        };

        // ì¶œë ¥ í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ (RGBA ë˜ëŠ” YUV420P)
        let frame = self.convert_frame(&raw_frame, timestamp_ms)?;

        // ë§ˆì§€ë§‰ ì„±ê³µ í”„ë ˆì„ ì €ì¥ (EOF/ì—ëŸ¬ ì‹œ fallback)
        self.last_decoded_frame = Some(frame.clone());
        self.state = DecoderState::Ready;

        Ok(DecodeResult::Frame(frame))
    }

    /// ë””ì½”ë”©ëœ ffmpeg Video í”„ë ˆì„ì„ ì¶œë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    /// - yuv_output=false: RGBA (í”„ë¦¬ë·°/ì¸ë„¤ì¼ìš©)
    /// - yuv_output=true: YUV420P ì§ì ‘ ì¶œë ¥ (Exportìš© â€” ìƒ‰ê³µê°„ ë³€í™˜ ì†ì‹¤ ì œê±°)
    /// bounds check ì¶”ê°€: FFmpegì´ ì†ìƒëœ í”„ë ˆì„ì„ ë°˜í™˜í•´ë„ panic ëŒ€ì‹  Err ë°˜í™˜
    fn convert_frame(&mut self, raw_frame: &ffmpeg::frame::Video, timestamp_ms: i64) -> Result<Frame, String> {
        let mut scaled_frame = ffmpeg::frame::Video::empty();
        self.scaler.run(raw_frame, &mut scaled_frame)
            .map_err(|e| format!("Failed to scale frame: {}", e))?;

        if self.yuv_output {
            self.extract_yuv_frame(&scaled_frame, timestamp_ms)
        } else {
            self.extract_rgba_frame(&scaled_frame, timestamp_ms)
        }
    }

    /// RGBA í”„ë ˆì„ ì¶”ì¶œ (í”„ë¦¬ë·°/ì¸ë„¤ì¼ìš©)
    fn extract_rgba_frame(&self, frame: &ffmpeg::frame::Video, timestamp_ms: i64) -> Result<Frame, String> {
        let size = (self.width * self.height * 4) as usize;
        let mut data = vec![0u8; size];

        let src_data = frame.data(0);
        let linesize = frame.stride(0);

        // ì•ˆì „ì„± ê²€ì¦
        let required_src_size = (self.height as usize - 1) * linesize + (self.width as usize * 4);
        if src_data.len() < required_src_size {
            return Err(format!(
                "Frame data too small: got {} bytes, need {} ({}x{}, stride={})",
                src_data.len(), required_src_size, self.width, self.height, linesize
            ));
        }

        if linesize < self.width as usize * 4 {
            return Err(format!(
                "Invalid stride: {} < {} (width * 4)",
                linesize, self.width as usize * 4
            ));
        }

        for y in 0..self.height as usize {
            let src_offset = y * linesize;
            let dst_offset = y * (self.width as usize * 4);
            let row_size = self.width as usize * 4;
            data[dst_offset..dst_offset + row_size]
                .copy_from_slice(&src_data[src_offset..src_offset + row_size]);
        }

        Ok(Frame {
            width: self.width,
            height: self.height,
            format: PixelFormat::RGBA,
            data,
            timestamp_ms,
        })
    }

    /// YUV420P í”„ë ˆì„ ì¶”ì¶œ (Exportìš© â€” ìƒ‰ê³µê°„ ë³€í™˜ ì—†ì´ ì§ì ‘ ì „ë‹¬)
    /// ë°ì´í„° ë ˆì´ì•„ì›ƒ: [Y plane: w*h][U plane: w/2*h/2][V plane: w/2*h/2]
    fn extract_yuv_frame(&self, frame: &ffmpeg::frame::Video, timestamp_ms: i64) -> Result<Frame, String> {
        let w = self.width as usize;
        let h = self.height as usize;
        let y_size = w * h;
        let half_w = w / 2;
        let half_h = h / 2;
        let uv_size = half_w * half_h;
        let total = y_size + uv_size * 2;
        let mut data = vec![0u8; total];

        // Y plane
        let y_data = frame.data(0);
        let y_stride = frame.stride(0);
        for row in 0..h {
            let src_offset = row * y_stride;
            let dst_offset = row * w;
            if src_offset + w <= y_data.len() {
                data[dst_offset..dst_offset + w]
                    .copy_from_slice(&y_data[src_offset..src_offset + w]);
            }
        }

        // U plane
        let u_data = frame.data(1);
        let u_stride = frame.stride(1);
        for row in 0..half_h {
            let src_offset = row * u_stride;
            let dst_offset = y_size + row * half_w;
            if src_offset + half_w <= u_data.len() {
                data[dst_offset..dst_offset + half_w]
                    .copy_from_slice(&u_data[src_offset..src_offset + half_w]);
            }
        }

        // V plane
        let v_data = frame.data(2);
        let v_stride = frame.stride(2);
        for row in 0..half_h {
            let src_offset = row * v_stride;
            let dst_offset = y_size + uv_size + row * half_w;
            if src_offset + half_w <= v_data.len() {
                data[dst_offset..dst_offset + half_w]
                    .copy_from_slice(&v_data[src_offset..src_offset + half_w]);
            }
        }

        Ok(Frame {
            width: self.width,
            height: self.height,
            format: PixelFormat::YUV420P,
            data,
            timestamp_ms,
        })
    }

    /// ë‹¤ìŒ í”„ë ˆì„ ë””ì½”ë”©
    pub fn decode_next_frame(&mut self) -> Result<Option<Frame>, String> {
        // TODO: êµ¬í˜„
        Ok(None)
    }

    /// ì¸ë„¤ì¼ í”„ë ˆì„ ìƒì„± (ì‘ì€ í•´ìƒë„ë¡œ ë””ì½”ë”©)
    ///
    /// NOTE:
    /// - ê¸°ì¡´ êµ¬í˜„ì€ seek í›„ "ì²« í”„ë ˆì„"ë§Œ ê°€ì ¸ì˜¤ëŠ” ë‹¨ìˆœ ë¡œì§ì´ë¼,
    ///   GOP êµ¬ì¡°ì— ë”°ë¼ ì—¬ëŸ¬ timestampê°€ ëª¨ë‘ ë™ì¼í•œ í‚¤í”„ë ˆì„ìœ¼ë¡œ
    ///   ë–¨ì–´ì§€ëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤.
    /// - ì—¬ê¸°ì„œëŠ” `decode_frame()`ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ íƒ€ì„ë¼ì¸ ë Œë”ëŸ¬ì™€
    ///   ë™ì¼í•œ ì‹œê°„ ë§¤í•‘ì„ ë”°ë¥´ê³ , ê·¸ ê²°ê³¼ RGBA í”„ë ˆì„ì„
    ///   thumb_width/heightë¡œ ë‹¨ìˆœ ì¶•ì†Œ(Nearest Neighbor)í•œë‹¤.
    pub fn generate_thumbnail(
        &mut self,
        timestamp_ms: i64,
        thumb_width: u32,
        thumb_height: u32,
    ) -> Result<Frame, String> {
        // 1) decode_frameìœ¼ë¡œ í•´ë‹¹ timestampì˜ RGBA í”„ë ˆì„ ì–»ê¸°
        let base_frame = match self.decode_frame(timestamp_ms)? {
            DecodeResult::Frame(f) => f,
            DecodeResult::EndOfStream(f) => f,
            DecodeResult::FrameSkipped => {
                match &self.last_decoded_frame {
                    Some(f) => f.clone(),
                    None => return Err("Failed to decode frame for thumbnail (FrameSkipped, no last frame)".into()),
                }
            }
            DecodeResult::EndOfStreamEmpty => {
                return Err("Failed to decode frame for thumbnail (EndOfStreamEmpty)".into());
            }
        };

        // 2) í¬ê¸°ê°€ ì´ë¯¸ ì›í•˜ëŠ” ì¸ë„¤ì¼ í¬ê¸°ë¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        //    (open_with_resolutionìœ¼ë¡œ ì—´ì—ˆìœ¼ë©´ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì´ë¯¸ thumb í¬ê¸°)
        if base_frame.width == thumb_width && base_frame.height == thumb_height {
            return Ok(base_frame);
        }

        // 3) í¬ê¸° ë¶ˆì¼ì¹˜ ì‹œ Nearest-Neighbor ë‹¤ìš´ìŠ¤ì¼€ì¼ (fallback)
        let src_w = base_frame.width as usize;
        let src_h = base_frame.height as usize;
        let dst_w = thumb_width as usize;
        let dst_h = thumb_height as usize;

        let mut data = vec![0u8; dst_w * dst_h * 4];

        for y in 0..dst_h {
            let src_y = y * src_h / dst_h;
            for x in 0..dst_w {
                let src_x = x * src_w / dst_w;

                let src_index = (src_y * src_w + src_x) * 4;
                let dst_index = (y * dst_w + x) * 4;

                data[dst_index..dst_index + 4]
                    .copy_from_slice(&base_frame.data[src_index..src_index + 4]);
            }
        }

        Ok(Frame {
            width: thumb_width,
            height: thumb_height,
            format: PixelFormat::RGBA,
            data,
            timestamp_ms,
        })
    }

    /// íŠ¹ì • ì‹œê°„ìœ¼ë¡œ seek (EOF/Error ìƒíƒœì—ì„œ ìë™ ë³µêµ¬)
    pub fn seek(&mut self, timestamp_ms: i64) -> Result<(), String> {
        // CRITICAL FIX: input_ctx.seek()ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ avformat_seek_file(ctx, -1, ...)ë¥¼ í˜¸ì¶œ
        // stream_index = -1 ì´ë©´ FFmpegì€ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ AV_TIME_BASE (ë§ˆì´í¬ë¡œì´ˆ) ë‹¨ìœ„ë¡œ í•´ì„
        // ì´ì „ ì½”ë“œëŠ” stream time_base ë‹¨ìœ„ë¡œ ë³€í™˜ â†’ seek ìœ„ì¹˜ê°€ ì™„ì „íˆ í‹€ë¦¼
        // (ì˜ˆ: 60ì´ˆë¥¼ 0.92ì´ˆë¡œ seek â†’ 59ì´ˆ ì „ì²´ë¥¼ forward decode â†’ ì„ í˜• ì„±ëŠ¥ ì €í•˜)
        let timestamp_us = timestamp_ms * 1000; // ms â†’ Î¼s (AV_TIME_BASE)

        match self.input_ctx.seek(timestamp_us, ..timestamp_us) {
            Ok(_) => {
                self.decoder.flush();
                // seek ì„±ê³µ â†’ Ready ìƒíƒœë¡œ ë³µêµ¬ (EOF/Errorì—ì„œ ë³µêµ¬)
                self.state = DecoderState::Ready;
                self.eof_timestamp_ms = None; // EOF ë§ˆì»¤ ì´ˆê¸°í™”
                Ok(())
            }
            Err(e) => {
                // seek ì‹¤íŒ¨ â†’ flush í›„ ì¬ì‹œë„ 1íšŒ
                self.decoder.flush();
                match self.input_ctx.seek(timestamp_us, ..timestamp_us) {
                    Ok(_) => {
                        self.decoder.flush();
                        self.state = DecoderState::Ready;
                        Ok(())
                    }
                    Err(_) => {
                        self.state = DecoderState::Error;
                        Err(format!("Seek failed after retry: {}", e))
                    }
                }
            }
        }
    }
}

/// PTSê°€ ëª©í‘œì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸ (ëª¨ë“ˆ ë ˆë²¨ í•¨ìˆ˜ - borrow checker ì¶©ëŒ ë°©ì§€)
/// target_info: Noneì´ë©´ ìˆœì°¨ ì¬ìƒ â†’ í•­ìƒ true (ì²« í”„ë ˆì„ ì¦‰ì‹œ ìˆ˜ë½)
/// target_info: Some((target_pts, tolerance_pts)) â†’ PTS >= target - tolerance ì´ë©´ true
fn is_pts_at_target(target_info: Option<(i64, i64)>, frame: &ffmpeg::frame::Video) -> bool {
    match target_info {
        None => true, // ìˆœì°¨ ì¬ìƒ: ë‹¤ìŒ í”„ë ˆì„ ë¬´ì¡°ê±´ ì‚¬ìš©
        Some((target_pts, tolerance_pts)) => {
            match frame.pts() {
                Some(pts) => pts >= target_pts - tolerance_pts,
                None => true, // PTS ì •ë³´ ì—†ìœ¼ë©´ ìˆ˜ë½
            }
        }
    }
}

// ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•˜ë¯€ë¡œ í…ŒìŠ¤íŠ¸ëŠ” ì£¼ì„ ì²˜ë¦¬
#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;

    #[test]
    #[ignore] // ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ í•„ìš”
    fn test_decoder_open() {
        let path = PathBuf::from("test.mp4");
        let decoder = Decoder::open(&path);
        assert!(decoder.is_ok());
    }

    #[test]
    #[ignore] // ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ í•„ìš”
    fn test_decode_frame() {
        let path = PathBuf::from("test.mp4");
        let mut decoder = Decoder::open(&path).unwrap();

        let result = decoder.decode_frame(1000);
        assert!(result.is_ok());

        let frame = match result.unwrap() {
            DecodeResult::Frame(f) | DecodeResult::EndOfStream(f) => f,
            DecodeResult::FrameSkipped | DecodeResult::EndOfStreamEmpty => {
                panic!("Expected a decoded frame, got {:?}", decoder.state());
            }
        };

        assert_eq!(frame.timestamp_ms, 1000);
        assert!(!frame.data.is_empty());
    }

    #[test]
    fn test_decoder_with_real_file() {
        // ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
        let path = PathBuf::from(r"C:\Users\USER\Videos\ë“œë¡  ëŒ€ì‘ 2.75ì¸ì¹˜ ë¡œì¼“ 'ë¹„ê¶'ìœ¼ë¡œ ìœ ë„í‚¤íŠ¸ ê°œë°œ, ì‚¬ìš°ë”” ê¸°ìˆ í˜‘ë ¥ ì¶”ì§„.mp4");

        if !path.exists() {
            println!("âš ï¸ Test video file not found, skipping test");
            return;
        }

        println!("\n=== Decoder Test ===");
        println!("ğŸ“¹ Opening video: {:?}", path);

        // 1. ë””ì½”ë” ì—´ê¸°
        let mut decoder = match Decoder::open(&path) {
            Ok(d) => {
                println!("âœ… Decoder opened successfully");
                println!("   Resolution: {}x{}", d.width(), d.height());
                println!("   FPS: {:.2}", d.fps());
                println!("   Duration: {}ms", d.duration_ms());
                d
            }
            Err(e) => {
                panic!("âŒ Failed to open decoder: {}", e);
            }
        };

        // 2. í”„ë ˆì„ ë””ì½”ë”© í…ŒìŠ¤íŠ¸ (0ms, 1000ms, 2000ms)
        let timestamps = [0i64, 1000, 2000];
        for timestamp in timestamps {
            println!("\nğŸ¬ Decoding frame at {}ms...", timestamp);
            match decoder.decode_frame(timestamp) {
                Ok(result) => {
                    let frame = match result {
                        DecodeResult::Frame(f) | DecodeResult::EndOfStream(f) => f,
                        DecodeResult::FrameSkipped | DecodeResult::EndOfStreamEmpty => {
                            panic!("Expected a decoded frame at {}ms, got {:?}", timestamp, decoder.state());
                        }
                    };

                    println!("   âœ… Frame decoded: {}x{}", frame.width, frame.height);
                    println!("   Data size: {} bytes", frame.data.len());

                    // ì²« 10í”½ì…€ í™•ì¸
                    let pixels: Vec<u8> = frame.data.iter().take(40).copied().collect();
                    println!("   First 10 pixels (RGBA): {:?}", pixels);

                    // ê²€ì¦
                    assert_eq!(frame.width, decoder.width());
                    assert_eq!(frame.height, decoder.height());
                    assert_eq!(frame.data.len(), (frame.width * frame.height * 4) as usize);
                    assert_eq!(frame.format, PixelFormat::RGBA);
                }
                Err(e) => {
                    panic!("âŒ Failed to decode frame at {}ms: {}", timestamp, e);
                }
            }
        }

        println!("\nâœ… All decoder tests passed!");
    }
}
